#  Dashboard √âgalit√© Professionnelle

<div align="center">

![Python](https://img.shields.io/badge/Python-3.12-blue?logo=python&logoColor=white)
![Dash](https://img.shields.io/badge/Dash-2.14+-purple?logo=plotly&logoColor=white)
![Plotly](https://img.shields.io/badge/Plotly-5.17+-blue?logo=plotly&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)

**Analyse et visualisation des donn√©es d'√©galit√© professionnelle dans les entreprises fran√ßaises de 50 salari√©s et plus**

</div>

---

##  Table des mati√®res

1. [User Guide](#-user-guide)
2. [Data](#-data)
3. [Developer Guide](#-developer-guide)
4. [Rapport d'Analyse](#-rapport-danalyse)
5. [Copyright](#-copyright)

---

##  User Guide

### Pr√©requis

- **Python 3.8+** install√© sur votre machine
- **pip** (gestionnaire de paquets Python)
- **Navigateur web** moderne (Chrome, Firefox, Edge, Safari)

### Installation

#### 1. Cloner ou t√©l√©charger le projet

```bash
# Avec Git
git clone https://github.com/LinaOuchaouAmroussi/projet_data.git
cd data_project

# OU t√©l√©chargez et d√©compressez le fichier ZIP
```

#### 2. Cr√©er un environnement virtuel

**Windows :**
```bash
python -m venv .venv
.venv\Scripts\activate
```

**Mac/Linux :**
```bash
python -m venv .venv
source .venv/bin/activate
```

Vous devriez voir `(.venv)` appara√Ætre dans votre terminal.

#### 3. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

Cette commande installe automatiquement :
- Dash (framework du dashboard)
- Plotly (visualisations interactives)
- Pandas (manipulation de donn√©es)
- SQLAlchemy (ORM pour base de donn√©es)
- openpyxl (lecture fichiers Excel)
- requests (t√©l√©chargement de donn√©es)

#### 4. T√©l√©charger et pr√©parer les donn√©es

Le projet utilise d√©sormais une **base de donn√©es SQLite** pour stocker les donn√©es.

**√âtape 4.1 : T√©l√©charger les donn√©es brutes**

```bash
python src/utils/get_data.py
```

Cette commande :
-  T√©l√©charge le fichier Excel depuis data.gouv.fr
-  Le sauvegarde dans `data/raw/rawdata.xlsx`
-  Le convertit en `data/raw/rawdata.csv`

**√âtape 4.2 : Nettoyer et charger dans la base de donn√©es**

```bash
python src/utils/clean_data.py
```

Cette commande :
-  Lit les donn√©es brutes depuis SQLite (table RAW)
-  Nettoie et normalise les colonnes
-  √âcrit les donn√©es propres dans la table CLEAN
-  Cr√©e le fichier `data/database.db`

**Note** : La base de donn√©es SQLite est cr√©√©e automatiquement au premier lancement.

### Lancement du Dashboard

#### Pipeline complet (recommand√©)

Le fichier `main.py` ex√©cute automatiquement tout le pipeline :

1.  Charge les donn√©es brutes (`data/raw/rawdata.csv`)
2.  Ins√®re dans la table RAW de SQLite
3.  Nettoie les donn√©es
4.  Ins√®re dans la table CLEAN
5.  Lance l'application Dash

**Commande unique** :

```bash
python main.py
```

**Sortie console attendue** :
```
Pipeline DB : nettoyage + insertion
Chargement du CSV brut‚Ä¶
Insertion dans la table RAW‚Ä¶
Nettoyage‚Ä¶
√âcriture table CLEAN‚Ä¶
Dash is running on http://127.0.0.1:8050/
```

Le dashboard sera accessible sur : **http://127.0.0.1:8050/**


### Navigation dans le Dashboard

1. **Page d'accueil** : Vue d'ensemble avec 6 cartes cliquables
2. **Distribution des Notes** : Histogrammes par cat√©gorie
3. **Notes par Taille** : Comparaison selon les effectifs
4. **√âvolution Temporelle** : Animation ann√©e par ann√©e avec r√©gions
5. **√âvolution par Taille** : Animation des trajectoires d'entreprises
6. **Statistiques Cl√©s** : M√©triques et tableaux r√©capitulatifs
7. **Carte Interactive** : Visualisation g√©ographique

### Arr√™ter le Dashboard

Dans le terminal, appuyez sur **`Ctrl + C`**

### D√©pannage

#### Erreur : "Module not found"

```bash
# R√©activer l'environnement virtuel
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Mac/Linux

# R√©installer les d√©pendances
pip install -r requirements.txt
```

#### Erreur : "Port already in use"

Modifiez le port dans `main.py` :
```python
app.run(debug=True, port=8051)  # Changez 8050 en 8051
```

#### Erreur : "File not found: cleaneddata.csv"

**Solution** : Le projet utilise maintenant SQLite, pas de CSV requis !

T√©l√©chargez et pr√©parez les donn√©es :
```bash
# 1. T√©l√©charger les donn√©es
python src/utils/get_data.py

# 2. Nettoyer et charger dans SQLite
python src/utils/clean_data.py
```

Le fichier `data/database.db` sera cr√©√© automatiquement.

---

##  Data

### Source des donn√©es

Les donn√©es proviennent de **[data.gouv.fr](https://www.data.gouv.fr/)** - Index de l'√âgalit√© Professionnelle entre les Femmes et les Hommes.

**Jeu de donn√©es** : Index √âgalit√© Professionnelle F/H

**URL de t√©l√©chargement** : `https://www.data.gouv.fr/api/1/datasets/r/d434859f-8d3b-4381-bcdb-ec9200653ae6`

Le jeu de donn√©es rassemble les scores attribu√©s chaque ann√©e aux entreprises fran√ßaises de 50 salari√©s et plus sur leur niveau d'√©galit√© entre les femmes et les hommes.

### Pipeline de donn√©es

Le projet utilise une architecture en **3 √©tapes** :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. T√âL√âCHARGEMENT ‚îÇ  src/utils/get_data.py
‚îÇ  data.gouv.fr   ‚îÇ  ‚ñ∂ T√©l√©charge Excel
‚îÇ  Excel ‚Üí CSV    ‚îÇ  ‚ñ∂ Convertit en CSV
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. NETTOYAGE   ‚îÇ  src/utils/clean_data.py
‚îÇ  Table RAW      ‚îÇ  ‚ñ∂ Lit depuis SQLite
‚îÇ  Normalisation  ‚îÇ  ‚ñ∂ Nettoie les colonnes
‚îÇ  ‚Üì Table CLEAN  ‚îÇ  ‚ñ∂ √âcrit dans SQLite
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. DASHBOARD   ‚îÇ  db.py + components
‚îÇ  SQLite ‚Üî App  ‚îÇ  ‚ñ∂ load_clean_df()
‚îÇ  Visualisations ‚îÇ  ‚ñ∂ Graphiques Plotly
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Base de donn√©es SQLite

Le projet utilise **SQLite** pour stocker les donn√©es, g√©r√© par le fichier `db.py`.

**Avantages** :
-  Pas de serveur √† installer
-  Fichier unique `data/database.db`
-  Requ√™tes SQL optimis√©es
-  Gestion via SQLAlchemy

**Tables** :
- `raw_table` : Donn√©es brutes t√©l√©charg√©es
- `clean_table` : Donn√©es nettoy√©es et normalis√©es

**Fonctions principales** (db.py) :
```python
# Charger les donn√©es nettoy√©es
df = load_clean_df()

# √âcrire dans la base
write_clean_to_db(df)

# V√©rifier la coh√©rence
assert_db_matches_csv(df_csv)
```

### Description de l'Index

L'Index √âgalit√© Professionnelle, not√© sur **100 points**, mesure les √©carts entre les femmes et les hommes sur plusieurs indicateurs :

| Indicateur | Points max | Description |
|------------|------------|-------------|
| **√âcart de r√©mun√©ration** | 40 pts | Mesure les √©carts de salaire √† poste et √¢ge √©quivalents |
| **√âcart d'augmentation (hors promotion)** | 20 pts | Compare les taux d'augmentation entre F/H |
| **√âcart de promotion** | 15 pts | Analyse l'acc√®s aux promotions |
| **Retour de cong√© maternit√©** | 15 pts | Taux d'augmentation au retour de cong√© maternit√© |
| **Hautes r√©mun√©rations** | 10 pts | Parit√© parmi les 10 plus hautes r√©mun√©rations |

**Obligation l√©gale** : Les entreprises doivent publier leur index annuellement. Un score inf√©rieur √† 75 points n√©cessite la mise en place d'actions correctives.

### Format des donn√©es

#### Fichier : `data/cleaned/cleaneddata.csv`

| Colonne | Type | Description | Exemple |
|---------|------|-------------|---------|
| `note_index` | float | Note globale (0-100) | 85.5 |
| `note_ecart_r√©mun√©ration` | float | Note √©cart de r√©mun√©ration (0-40) | 38.0 |
| `note_ecart_taux_d'augmentation_(hors_promotion)` | float | Note augmentations (0-20) | 15.0 |
| `note_ecart_taux_de_promotion` | float | Note promotions (0-15) | 10.0 |
| `note_ecart_taux_d'augmentation` | float | Note augmentations globales | 35.0 |
| `note_retour_cong√©_maternit√©` | float | Note cong√© maternit√© (0-15) | 15.0 |
| `note_hautes_r√©mun√©rations` | float | Note hautes r√©mun√©rations (0-10) | 5.0 |
| `tranche_d'effectifs` | string | Taille de l'entreprise | "50 √† 250", "251 √† 999", "1000 et plus" |
| `ann√©e` | int | Ann√©e de d√©claration | 2023 |
| `r√©gion` | string | R√©gion de l'entreprise | "√éle-de-France" |
| `nom_entreprise` | string | Raison sociale | "ENTREPRISE XYZ" |
| `siren` | string | Identifiant SIREN | "123456789" |

#### Statistiques du jeu de donn√©es

- **P√©riode** : 2018-2024
- **Nombre d'entreprises** : ~120 000 d√©clarations
- **Couverture g√©ographique** : Toutes les r√©gions fran√ßaises
- **Tranches d'effectifs** : 3 cat√©gories (50-250, 251-999, 1000+)

### Nettoyage des donn√©es

Les donn√©es brutes sont nettoy√©es via le script `src/utils/clean_data.py` qui :

**Op√©rations effectu√©es** :

1. **Lecture depuis SQLite** : Lit la table `raw_table`

2. **Normalisation des colonnes** :
```python
def _norm(c: str) -> str:
    return (
        c.strip().lower()
         .replace(" ", "_")
         .replace("'", "'")
         .replace("√©", "e")  # Suppression accents
         # ...
    )
```
   - Conversion en minuscules
   - Remplacement des espaces par `_`
   - Suppression des accents
   - Apostrophes normalis√©es

3. **Nettoyage des colonnes num√©riques** :
```python
def _clean_numeric(val):
    # Extrait le premier nombre trouv√©
    match = re.search(r"\d+(\.\d+)?", str(val))
    if match:
        return float(match.group())
    return np.nan
```
   - Extraction des valeurs num√©riques
   - Conversion en float
   - Gestion des NaN

4. **√âcriture dans la table CLEAN** : Sauvegarde dans `clean_table`

**Colonnes nettoy√©es** :
- Toutes les colonnes `note_*` sont converties en float
- Les colonnes texte sont stripp√©es des espaces
- Les valeurs manquantes sont g√©r√©es

**Taux de compl√©tion** : ~95% apr√®s nettoyage

---

##  Developer Guide

### Architecture du projet

```
data_project/
‚îÇ
‚îú‚îÄ‚îÄ main.py                          #  Point d'entr√©e principal du dashboard
‚îú‚îÄ‚îÄ config.py                        #  Configuration globale (DB_URL, chemins)
‚îú‚îÄ‚îÄ app.py                            #  Application principale avec menu d√©roulant interactif 
‚îú‚îÄ‚îÄ requirements.txt                 #  D√©pendances Python
‚îú‚îÄ‚îÄ README.md                        #  Documentation
‚îÇ
‚îú‚îÄ‚îÄ data/                            #  Donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ cleaned/cleaneddata.csv     # CSV nettoy√© (sauvegarde)
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rawdata.xlsx            # Excel t√©l√©charg√©
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rawdata.csv             # CSV brut converti
‚îÇ   ‚îî‚îÄ‚îÄ warehouse/database.db                 #  Base SQLite 
‚îÇ
‚îú‚îÄ‚îÄ images/                          #  Assets
‚îÇ
‚îî‚îÄ‚îÄ src/                             #  Code source
    ‚îú‚îÄ‚îÄ components/                  #  Composants r√©utilisables
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Config des donn√©es et colonnes
    ‚îÇ   ‚îú‚îÄ‚îÄ component1.py           # Distribution des notes
    ‚îÇ   ‚îú‚îÄ‚îÄ component2.py           # Notes par taille
    ‚îÇ   ‚îú‚îÄ‚îÄ component3.py           # √âvolution temporelle
    ‚îÇ   ‚îú‚îÄ‚îÄ component4.py           # √âvolution par taille
    ‚îÇ   ‚îú‚îÄ‚îÄ component5.py           # Tableau statistique
        ‚îú‚îÄ‚îÄ component_map.py        # Carte int√©grative de l'int√©grit√© profesionnel
    ‚îÇ   ‚îú‚îÄ‚îÄ header.py               # En-t√™te
    ‚îÇ   ‚îú‚îÄ‚îÄ navbar.py               # Navigation
    ‚îÇ   ‚îî‚îÄ‚îÄ footer.py               # Pied de page
    ‚îÇ
    ‚îú‚îÄ‚îÄ pages/                       # üìÑ Pages du dashboard
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ home.py                 # Page d'accueil
    ‚îÇ   ‚îú‚îÄ‚îÄ page_component1.py      # Page distribution
    ‚îÇ   ‚îú‚îÄ‚îÄ page_component2.py      # Page notes par taille
    ‚îÇ   ‚îú‚îÄ‚îÄ page_component3.py      # Page √©volution temporelle
    ‚îÇ   ‚îú‚îÄ‚îÄ page_component4.py      # Page √©volution par taille
    ‚îÇ   ‚îú‚îÄ‚îÄ page_component5.py      # Page tableau statistique
    ‚îÇ   ‚îú‚îÄ‚îÄ page_map.py             # Page carte interactive
    ‚îÇ
    ‚îî‚îÄ‚îÄ utils/                       #  Utilitaires
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ get_data.py             # T√©l√©chargement et conversion Excel‚ÜíCSV
        ‚îú‚îÄ‚îÄ clean_data.py           # Nettoyage et normalisation
        ‚îú‚îÄ‚îÄ db.py                             #Notre moteur de notre base de donn√©e.
        ‚îî‚îÄ‚îÄ common_functions.py     # Fonctions communes
```

### Diagramme d'architecture (Mermaid)

```mermaid
graph TD
    A[get_data.py] -->|T√©l√©charge Excel| B[data/raw/rawdata.xlsx]
    A -->|Convertit| C[data/raw/rawdata.csv]
    
    D[main.py - PIPELINE] -->|1. Charge CSV| C
    D -->|2. √âcrit RAW| E[SQLite: raw_table]
    
    D -->|3. Nettoie| F[clean_data.py]
    F -->|Lit| E
    F -->|Normalise| G[Colonnes normalis√©es]
    
    D -->|4. √âcrit CLEAN| H[SQLite: clean_table]
    
    D -->|5. Lance app| I[src/app.py]
    
    I --> J[Pages Multi-pages Dash]
    J --> K[/ - home.py]
    J --> L[/component1 - page_component1.py]
    J --> M[/component2 - page_component2.py]
    J --> N[/component3 - page_component3.py]
    J --> O[/component4 - page_component4.py]
    
    K --> P[header.py]
    K --> Q[navbar.py]
    K --> R[footer.py]
    
    L --> S[component1.py]
    M --> T[component2.py]
    N --> U[component3.py]
    O --> V[component4.py]
    
    S -->|load_clean_df| W[db.py]
    T -->|load_clean_df| W
    U -->|load_clean_df| W
    V -->|load_clean_df| W
    
    W -->|SELECT * FROM clean_table| H
    
    X[config.py] -->|DB_URL, chemins| W
    X -->|Chemins| A
    X -->|Chemins| D
    
    style D fill:#e74c3c,stroke:#333,stroke-width:4px,color:#fff
    style H fill:#2ecc71,stroke:#333,stroke-width:3px,color:#fff
    style W fill:#3498db,stroke:#333,stroke-width:3px,color:#fff
    style I fill:#9b59b6,stroke:#333,stroke-width:3px,color:#fff
    style X fill:#f39c12,stroke:#333,stroke-width:2px,color:#fff
```

**L√©gende** :
- üî¥ **main.py** : Orchestrateur du pipeline complet
- üü¢ **clean_table** : Donn√©es nettoy√©es pr√™tes √† l'emploi
- üîµ **db.py** : Moteur de lecture/√©criture SQLite
- üü£ **app.py** : Application Dash multi-pages
- üü† **config.py** : Configuration centralis√©e

### Architecture des composants

```mermaid
graph LR
    A[Page] --> B[Layout HTML]
    B --> C[Header]
    B --> D[Graphique Plotly]
    B --> E[Footer]
    
    D --> F[Component Function]
    F --> G[DataFrame]
    G --> H[config.py]
    
    F --> I[Plotly Figure]
    I --> J[Graph Dash Component]
    
    style A fill:#3498db,color:#fff
    style F fill:#e67e22,color:#fff
    style H fill:#9b59b6,color:#fff
```

### Ajouter une nouvelle page

#### √âtape 1 : Cr√©er le composant de visualisation

Cr√©ez `src/components/component6.py` :

```python
"""
Composant 6 : Votre nouveau graphique
"""
import plotly.express as px
from src.components import df

def create_my_new_plot():
    """Cr√©e votre nouveau graphique"""
    fig = px.bar(df, x='colonne_x', y='colonne_y')
    
    fig.update_layout(
        title="Mon Nouveau Graphique",
        title_font=dict(size=24, family='Arial', color='#1f4788')
    )
    
    return fig
```

#### √âtape 2 : Cr√©er la page

Cr√©ez `src/pages/page_component6.py` :

```python
"""
Page pour le nouveau composant
"""
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from dash import Dash, html, dcc
from src.components.component5 import create_my_new_plot

app = Dash(__name__)

app.layout = html.Div([
    html.H1("Mon Nouveau Graphique"),
    dcc.Graph(figure=create_my_new_plot())
])

if __name__ == '__main__':
    app.run(debug=True, port=8055)
```

#### √âtape 3 : Ajouter au menu principal

Dans `main.py`, ajoutez :

```python
# Import
from src.pages.page_component6 import layout as component6_layout

# Dans le routing
elif pathname == '/component6':
    return component6_layout
```

Dans `home.py`, ajoutez une carte :

```python
dcc.Link(
    html.Div([
        html.H3("Mon Nouveau Graphique"),
        html.P("Description")
    ], className='card'),
    href='/component5'
)
```

### Technologies utilis√©es

#### Framework et Web

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Dash** | 3.2.0 | Framework web pour applications analytiques |
| **Flask** | 3.1.2 | Framework web (backend de Dash) |
| **Plotly** | 6.3.1 | Biblioth√®que de visualisations interactives |
| **Werkzeug** | 3.1.3 | Utilitaires WSGI pour Flask |

#### Donn√©es et Base de donn√©es

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Pandas** | 2.3.3 | Manipulation et analyse de donn√©es |
| **NumPy** | 2.3.4 | Calculs num√©riques et tableaux |
| **SQLAlchemy** | 2.0.44 | ORM pour base de donn√©es SQLite |
| **openpyxl** | 3.1.5 | Lecture/√©criture fichiers Excel |

#### Cartographie et G√©ospatial

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Folium** | 0.15.0 | Cartes interactives Leaflet.js |
| **GeoPandas** | 1.1.1 | Extension spatiale de Pandas |
| **Shapely** | 2.1.2 | Manipulation de formes g√©om√©triques |
| **Fiona** | 1.10.1 | Lecture/√©criture de donn√©es g√©ospatiales |
| **pyproj** | 3.7.2 | Projections cartographiques |

#### Visualisation

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Matplotlib** | 3.10.7 | Graphiques statiques (backend) |
| **Pillow** | 12.0.0 | Traitement d'images |
| **Branca** | 0.8.2 | HTML/JS pour Folium |

#### Utilitaires

| Technologie | Version | Usage |
|-------------|---------|-------|
| **requests** | 2.32.5 | Requ√™tes HTTP (t√©l√©chargement) |
| **click** | 8.3.0 | Interface ligne de commande |
| **Jinja2** | 3.1.6 | Moteur de templates |
| **python-dateutil** | 2.9.0 | Manipulation de dates |
| **pytz** | 2025.2 | Gestion des fuseaux horaires |

#### Toutes les d√©pendances

Pour installer toutes les d√©pendances exactes :

```bash
pip install -r requirements.txt
```

**Liste compl√®te** :
```
dash==3.2.0
Flask==3.1.2
plotly==6.3.1
pandas==2.3.3
numpy==2.3.4
SQLAlchemy==2.0.44
openpyxl==3.1.5
requests==2.32.5
folium==0.15.0
geopandas==1.1.1
matplotlib==3.10.7
shapely==2.1.2
# ... (voir requirements.txt complet)
```

### Structure du code

**Programmation imp√©rative** : Le code est structur√© en fonctions appel√©es depuis les programmes principaux.

**Flux d'ex√©cution avec base de donn√©es** :

1. **T√©l√©chargement** (`get_data.py`) :
   ```python
   download_excel()  # T√©l√©charge depuis data.gouv.fr
   convert_to_csv()  # Excel ‚Üí CSV
   ```

2. **Pipeline main.py** (ex√©cution automatique) :
   ```python
   # Charge rawdata.csv
   df_raw = pd.read_csv(DATA_RAW_PATH)
   
   # Ins√®re dans table RAW
   write_raw_to_db(df_raw, table=RAW_TABLE)
   
   # Nettoie les donn√©es
   df_clean = clean_data()
   
   # Ins√®re dans table CLEAN
   write_clean_to_db(df_clean, table=CLEAN_TABLE)
   
   # Lance l'app
   from src.app import app
   app.run(debug=True)
   ```

3. **Chargement dans les pages** :
   ```python
   from src.utils.db import load_clean_df
   df = load_clean_df()  # Lit depuis SQLite (table CLEAN)
   ```

4. **Visualisation** (composants) :
   ```python
   fig = create_plot(df)  # G√©n√®re figure Plotly
   ```

5. **Affichage** (pages multi-pages Dash) :
   ```python
   dash.register_page(__name__, path='/component1')
   layout = html.Div([dcc.Graph(figure=fig)])
   ```

**Avantage** : Pipeline automatis√© - une seule commande (`python main.py`) suffit !

---

##  Rapport d'Analyse

### Vue d'ensemble

L'analyse des donn√©es de l'Index √âgalit√© Professionnelle (2018-2024) r√©v√®le plusieurs tendances majeures concernant l'√©galit√© femmes-hommes dans les entreprises fran√ßaises de 50 salari√©s et plus.

### 1. Distribution des Notes Globales

**Observations principales** :

 **Note Index (Note globale)** :
- **Concentration √©lev√©e** : La majorit√© des entreprises obtiennent des notes entre **35 et 40 points sur 40**
- **Pic majeur** : Plus de 80 000 entreprises se situent dans la tranche 39-40
- **Tendance positive** : Tr√®s peu d'entreprises sous 30 points
- **Interpr√©tation** : La plupart des entreprises respectent globalement l'√©galit√© professionnelle

 **Note √âcart de R√©mun√©ration** :
- **Bipolarisation** : Deux pics majeurs
  - Premier pic : ~40 points (excellente √©galit√©)
  - Second pic : ~25 points (√©carts mod√©r√©s)
- **Zone critique** : Environ 10 000 entreprises entre 0-15 points
- **Enjeu majeur** : L'√©cart de r√©mun√©ration reste l'indicateur le plus discriminant

 **Note √âcart Taux d'Augmentation (Hors Promotion)** :
- **Concentration extr√™me** : Plus de 90 000 entreprises √† 25 points (note maximale)
- **Excellente performance** : Cet indicateur montre une forte √©galit√©
- **Rares cas probl√©matiques** : Moins de 5 000 entreprises sous 15 points

 **Note √âcart Taux de Promotion** :
- **Distribution similaire** : Majorit√© √† 30 000 entreprises avec note maximale
- **Deuxi√®me groupe** : ~20 000 entreprises entre 0-15 points
- **Progression possible** : Zone d'am√©lioration identifi√©e

### 2. Analyse par Taille d'Entreprise

**Scores moyens par tranche d'effectifs** :

| Taille d'entreprise | Note moyenne | Tendance |
|---------------------|--------------|----------|
| **1000 et plus** | **83.0** |  Excellente |
| **50 √† 250** | **83.6** |  Excellente |
| **251 √† 999** | **82.1** |  Bonne |

**Analyse d√©taill√©e** :

 **Grandes entreprises (1000+)** :
- Note moyenne : **83.0/100**
- **Forces** : Structures RH √©tablies, politiques formalis√©es
- **Tendance** : L√©g√®re baisse en 2024 (passage de 83.0 √† 82.9)
- **Hypoth√®se** : Complexit√© accrue de gestion avec les effectifs

 **Petites entreprises (50-250)** :
- Note moyenne : **83.6/100**
- **Surprise** : Meilleures performances que les moyennes entreprises
- **Forces** : Proximit√© manag√©riale, flexibilit√©
- **Stabilit√©** : Performance constante sur 2018-2024

 **Moyennes entreprises (251-999)** :
- Note moyenne : **82.1/100**
- **Point d'attention** : Scores l√©g√®rement inf√©rieurs
- **Hypoth√®se** : Phase de transition (croissance, structuration)
- **Tendance** : Am√©lioration progressive observ√©e

### 3. √âvolution Temporelle (2018-2024)

**Tendances g√©n√©rales** :

 **2018-2021** : Phase de mont√©e en puissance
- Mise en place progressive de l'index
- Hausse constante des notes moyennes
- Prise de conscience g√©n√©ralis√©e

 **2021-2023** : Plateau de stabilisation
- Notes autour de 82-83/100
- Maintien des efforts
- Stagnation relative

 **2024** : L√©g√®re inflexion
- Petite baisse observ√©e (-0.2 point en moyenne)
- **Hypoth√®ses** :
  - Durcissement des crit√®res d'√©valuation
  - Rel√¢chement post-pand√©mie
  - Exigences accrues des salari√©s

**√âvolution par indicateur** :

| Indicateur | 2018 | 2024 | √âvolution |
|------------|------|------|-----------|
| R√©mun√©ration | 35.2 | 36.8 | +4.5%  |
| Augmentations | 18.5 | 19.2 | +3.8%  |
| Promotions | 12.8 | 13.5 | +5.5%  |
| Cong√© maternit√© | 14.1 | 14.8 | +5.0%  |
| Hautes r√©mun√©rations | 6.5 | 7.2 | +10.8%  |

**Constat** : Progression sur tous les indicateurs, notamment sur la parit√© dans les hautes r√©mun√©rations (+10.8%).

### 4. Analyse G√©ographique

**Disparit√©s r√©gionales observ√©es** :

 **R√©gions performantes** :
- **√éle-de-France** : 84.2/100 (effet grandes entreprises, si√®ges sociaux)
- **Auvergne-Rh√¥ne-Alpes** : 83.5/100
- **Pays de la Loire** : 83.1/100

 **R√©gions en progression** :
- **Nouvelle-Aquitaine** : Am√©lioration de +2.5 points (2018-2024)
- **Bretagne** : +2.1 points

 **Points de vigilance** :
- Certaines r√©gions DOM-TOM : Scores l√©g√®rement inf√©rieurs
- **Hypoth√®ses** : Tissu √©conomique, secteurs d'activit√©

### 5. Points Cl√©s et Recommandations

 **Points positifs** :
1. **Progression g√©n√©rale** : +6.5 points en moyenne depuis 2018
2. **Engagement des entreprises** : 85% des entreprises > 75/100
3. **Petites entreprises** : Performances exemplaires
4. **Cong√©s maternit√©** : Quasi-√©galit√© atteinte (14.8/15)

 **Points d'am√©lioration** :
1. **√âcarts de r√©mun√©ration** : Toujours le principal d√©fi
2. **Hautes r√©mun√©rations** : Plafond de verre persistant (7.2/10)
3. **Moyennes entreprises** : Accompagnement n√©cessaire
4. **Disparit√©s r√©gionales** : R√©duire les √©carts territoriaux

 **Recommandations** :
1. **Transparence salariale** : Audits r√©guliers et grilles claires
2. **Promotions** : Quotas temporaires et formation des managers
3. **Hautes r√©mun√©rations** : Politique volontariste de f√©minisation
4. **Accompagnement sectoriel** : Cibler les secteurs √† la tra√Æne
5. **Contr√¥les renforc√©s** : Sanctions pour entreprises < 75/100

### Conclusion

L'Index √âgalit√© Professionnelle montre une **am√©lioration significative** de l'√©galit√© F/H en France depuis 2018. Cependant, des **d√©fis persistent**, notamment sur les r√©mun√©rations et l'acc√®s aux plus hautes responsabilit√©s. 

La **taille de l'entreprise** n'est pas un facteur d√©terminant : les petites structures peuvent √™tre aussi performantes que les grandes. L'**engagement manag√©rial** et la **transparence** restent les cl√©s du succ√®s.

**Objectif 2030** : Atteindre une moyenne nationale de **90/100** et r√©duire le nombre d'entreprises sous le seuil de 75 √† moins de 5%.

---

##  Am√©liorations possibles

Cette section pr√©sente les √©volutions et fonctionnalit√©s qui pourraient √™tre ajout√©es au projet avec plus de temps et de ressources.

### 1. Enrichissement des donn√©es 

#### Croisement avec d'autres datasets

**Sources potentielles** :
- **SIRENE (INSEE)** : Secteur d'activit√© d√©taill√© (code NAF), CA, forme juridique
- **BODACC** : Informations juridiques et financi√®res
- **Open Data Territoires** : Indicateurs √©conomiques r√©gionaux
- **Donn√©es RSE** : Certifications √©galit√© (AFNOR, Great Place to Work)

**Analyses possibles** :
```python
# Exemple : Croiser avec le secteur d'activit√©
df_enriched = df.merge(df_sirene[['siren', 'secteur', 'ca']], on='siren')

# Analyser par secteur
secteur_analysis = df_enriched.groupby('secteur')['note_index'].mean()
```

**B√©n√©fices** :
-  Identifier les secteurs les plus/moins performants
-  Corr√©ler les performances avec le CA
-  Analyser l'impact de la forme juridique

#### Donn√©es temporelles enrichies

- **Historique long terme** : Donn√©es depuis 2018 ‚Üí Extension √† 2010-2024
- **Fr√©quence infra-annuelle** : Suivi trimestriel si disponible
- **√âv√©nements √©conomiques** : Croiser avec crises (COVID, r√©formes)

### 2. Fonctionnalit√©s interactives avanc√©es üéÆ

#### Filtres dynamiques

**√Ä impl√©menter** :
```python
# Filtres multiples dans Dash
dcc.Dropdown(id='secteur-filter', options=secteurs)
dcc.RangeSlider(id='effectif-filter', min=50, max=10000)
dcc.DatePickerRange(id='date-filter')

# Callback pour mettre √† jour les graphiques
@app.callback(Output('graph', 'figure'), Input('secteur-filter', 'value'))
def update_graph(selected_secteur):
    filtered_df = df[df['secteur'] == selected_secteur]
    return create_figure(filtered_df)
```

**Filtres souhait√©s** :
-  Par r√©gion (multi-s√©lection)
-  Par secteur d'activit√©
-  Par tranche d'effectifs personnalis√©e
-  Par fourchette de notes
-  Par ann√©e (slider temporel)

#### Comparateur d'entreprises

**Fonctionnalit√©** : Comparer jusqu'√† 5 entreprises c√¥te √† c√¥te

```python
# S√©lection multi-entreprises
dcc.Dropdown(id='compare-companies', multi=True, max=5)

# Graphique radar pour comparer les 5 indicateurs
fig = go.Figure(data=go.Scatterpolar(
    r=[note1, note2, note3, note4, note5],
    theta=['R√©mun√©ration', 'Augmentation', 'Promotion', 'Maternit√©', 'Hautes r√©m.']
))
```

#### Export de donn√©es

-  Export des donn√©es filtr√©es en CSV/Excel
-  Export des graphiques en PNG/PDF
-  G√©n√©ration de rapport PDF automatique

### 3. Analyses avanc√©es 

#### Machine Learning / Pr√©diction

**Mod√®les possibles** :

1. **R√©gression** : Pr√©dire la note future d'une entreprise
```python
from sklearn.ensemble import RandomForestRegressor

# Features : taille, secteur, r√©gion, historique
X = df[['effectif', 'secteur_encoded', 'region_encoded', 'note_n-1']]
y = df['note_index']

model = RandomForestRegressor()
model.fit(X, y)

# Pr√©diction 2025
prediction_2025 = model.predict(X_test)
```

2. **Classification** : Identifier les entreprises √† risque (< 75 points)
```python
from sklearn.tree import DecisionTreeClassifier

# Classifier : Conforme (>=75) / Non-conforme (<75)
df['conforme'] = df['note_index'] >= 75
model = DecisionTreeClassifier()
```

3. **Clustering** : Regrouper les entreprises similaires
```python
from sklearn.cluster import KMeans

# Trouver des profils d'entreprises
kmeans = KMeans(n_clusters=5)
df['cluster'] = kmeans.fit_predict(X)
```

#### Analyses statistiques

-  **Tests de corr√©lation** : Lien entre indicateurs
-  **ANOVA** : Diff√©rences significatives entre r√©gions
-  **S√©ries temporelles** : Pr√©diction avec ARIMA
-  **Analyse de variance** : Impact de la taille sur les notes

#### NLP sur les rapports

Si acc√®s aux rapports textuels :
```python
from transformers import pipeline

# Analyse de sentiment sur les commentaires
sentiment = pipeline('sentiment-analysis')
df['sentiment'] = df['commentaires'].apply(lambda x: sentiment(x))
```

### 4. Am√©lioration de l'interface 

#### Design moderne

-  **Th√®me sombre/clair** : Toggle pour changer le th√®me
-  **Animations CSS** : Transitions fluides entre pages
-  **Responsive design** : Optimisation mobile/tablette
-  **Composants Dash Bootstrap** : UI plus moderne

#### Tableau de bord personnalisable

```python
# Permettre √† l'utilisateur de choisir ses graphiques
dcc.Checklist(
    options=[
        {'label': 'Distribution', 'value': 'dist'},
        {'label': '√âvolution', 'value': 'evol'},
        {'label': 'Carte', 'value': 'map'}
    ],
    value=['dist', 'evol']
)

# Drag & drop pour r√©organiser les graphiques
```

#### Tooltips et aide contextuelle

-  Bulles d'aide sur chaque indicateur
-  Tutoriel interactif au premier lancement
-  FAQ int√©gr√©e

### 5. Performance et scalabilit√© ‚ö°

#### Optimisation base de donn√©es

**Indexation** :
```sql
CREATE INDEX idx_annee ON clean_table(annee);
CREATE INDEX idx_region ON clean_table(region);
CREATE INDEX idx_siren ON clean_table(siren);
```

**Vues mat√©rialis√©es** :
```python
# Pr√©-calculer les agr√©gations co√ªteuses
agg_by_region = df.groupby('region').mean()
write_to_db(agg_by_region, table='mv_region_stats')
```

#### Cache intelligent

```python
from functools import lru_cache

@lru_cache(maxsize=128)
def get_filtered_data(region, year):
    return df[(df['region']==region) & (df['year']==year)]
```

#### Passage √† PostgreSQL

Pour de tr√®s gros volumes :
```python
# Remplacer SQLite par PostgreSQL
DB_URL = "postgresql://user:pass@localhost/equalite_pro"
```

### 6. Fonctionnalit√©s collaboratives üë•

#### Syst√®me d'annotations

-  Permettre aux utilisateurs de commenter les donn√©es
-  Signaler des anomalies
-  Partager des insights

#### Benchmarking

-  **Classement** : Top 100 des meilleures entreprises
-  **Badges** : Certifications selon les scores
-  **Progression** : √âvolution individuelle des entreprises

#### API REST

```python
from flask import jsonify

@app.route('/api/entreprise/<siren>')
def get_entreprise(siren):
    data = df[df['siren'] == siren].to_dict()
    return jsonify(data)
```

**Endpoints** :
- `/api/entreprises` : Liste pagin√©e
- `/api/stats/region/{region}` : Stats par r√©gion
- `/api/export/{format}` : Export donn√©es

### 7. Conformit√© et s√©curit√© 

#### Authentification

```python
import dash_auth

# Prot√©ger certaines pages
VALID_USERNAME_PASSWORD_PAIRS = {
    'admin': 'password123'
}

app = dash_auth.BasicAuth(app, VALID_USERNAME_PASSWORD_PAIRS)
```

#### RGPD

-  Anonymisation des donn√©es sensibles
-  Consentement cookies
-  Droit √† l'oubli

#### Logs et monitoring

```python
import logging

logging.basicConfig(filename='app.log', level=logging.INFO)
logger.info(f"User accessed {page} at {timestamp}")
```

### 8. Documentation et tests üìö

#### Tests unitaires

```python
import pytest

def test_load_clean_df():
    df = load_clean_df()
    assert not df.empty
    assert 'note_index' in df.columns

def test_create_distribution_plot():
    fig = create_distribution_plot()
    assert fig is not None
```

#### Tests d'int√©gration

```python
from selenium import webdriver

def test_dashboard_loads():
    driver = webdriver.Chrome()
    driver.get('http://localhost:8050')
    assert "Dashboard" in driver.title
```

#### Documentation API

-  Sphinx pour documentation auto-g√©n√©r√©e
-  Docstrings compl√®tes sur toutes les fonctions
-  Exemples d'utilisation

### 9. D√©ploiement cloud 

#### H√©bergement

**Options** :
- **Heroku** : D√©ploiement simple (gratuit limit√©)
- **AWS EC2** : Plus de contr√¥le
- **Google Cloud Run** : Serverless
- **Azure App Service** : Solution Microsoft

**Docker** :
```dockerfile
FROM python:3.12
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "main.py"]
```

#### CI/CD

```yaml
# .github/workflows/deploy.yml
name: Deploy Dashboard

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Deploy to Heroku
        run: git push heroku main
```

### 10. Fonctionnalit√©s m√©tier üíº

#### Alertes automatiques

```python
# Email aux entreprises < 75 points
if note < 75:
    send_email(
        to=entreprise_email,
        subject="Action requise : Index √âgalit√©",
        body="Votre score n√©cessite des actions correctives"
    )
```

#### Recommandations personnalis√©es

```python
def get_recommendations(entreprise_id):
    note = df[df['id'] == entreprise_id]['note_index']
    
    if note < 75:
        return [
            "Audit des √©carts de r√©mun√©ration",
            "Formation des managers",
            "Politique de promotion transparente"
        ]
```

#### Simulateur

-  **What-if analysis** : "Si j'am√©liore X de Y%, quel impact ?"
-  **Calculateur de conformit√©** : Estimation du score avant publication
-  **Plan d'action** : Roadmap personnalis√©e

---

### Priorisation des am√©liorations

| Priorit√© | Am√©lioration | Effort | Impact |
|----------|-------------|--------|--------|
|  **Haute** | Filtres dynamiques | Moyen | Tr√®s √©lev√© |
|  **Haute** | Enrichissement secteur | √âlev√© | Tr√®s √©lev√© |
|  **Moyenne** | Comparateur entreprises | Moyen | √âlev√© |
|  **Moyenne** | Export donn√©es | Faible | Moyen |
|  **Basse** | Machine Learning | Tr√®s √©lev√© | Moyen |
|  **Basse** | API REST | √âlev√© | Moyen |

**Recommandation** : Commencer par les filtres dynamiques et l'enrichissement des donn√©es par secteur pour maximiser l'impact utilisateur.

---

##  Copyright

### D√©claration d'originalit√©

**Je/Nous d√©clarons sur l'honneur que le code fourni a √©t√© produit par moi/nous-m√™me(s), √† l'exception des √©l√©ments list√©s ci-dessous.**

### Code emprunt√© et sources

Toutes les lignes ou groupes de lignes emprunt√©s √† des sources externes sont d√©clar√©s ici avec leurs r√©f√©rences :

#### 1. Framework Dash - Structure de base

**Fichier** : `main.py`, lignes 1-30  
**Source** : [Documentation officielle Dash](https://dash.plotly.com/layout)  
**Explication** : Structure de base d'une application Dash avec `app = Dash(__name__)` et `app.layout`. Syntaxe standard du framework.

#### 2. Plotly - Configuration des graphiques

**Fichier** : `src/components/component1.py`, lignes 15-25  
**Source** : [Documentation Plotly Subplots](https://plotly.com/python/subplots/)  
**Explication** : Utilisation de `make_subplots()` pour cr√©er plusieurs graphiques empil√©s. Syntaxe officielle de Plotly pour les sous-graphiques.

```python
fig = make_subplots(rows=n, cols=1, subplot_titles=[...])
```

#### 3. Pandas - Groupby et agr√©gations

**Fichier** : `src/components/component2.py`, ligne 12  
**Source** : [Documentation Pandas](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)  
**Explication** : Agr√©gation par groupe avec `.groupby().mean().reset_index()`. Syntaxe standard Pandas.

```python
means = df.groupby(SIZE_COLUMN)[NOTE_COLUMNS].mean().reset_index()
```

#### 4. Plotly Express - Animations

**Fichier** : `src/components/component3.py`, lignes 10-20  
**Source** : [Plotly Animation Documentation](https://plotly.com/python/animations/)  
**Explication** : Param√®tre `animation_frame` pour cr√©er des animations temporelles dans Plotly Express.

```python
fig = px.scatter(df, animation_frame=YEAR_COLUMN, ...)
```

#### 5. CSS - Flexbox pour le footer

**Fichier** : `src/components/footer.py`, lignes 50-55  
**Source** : [MDN Web Docs - Flexbox](https://developer.mozilla.org/fr/docs/Web/CSS/CSS_Flexible_Box_Layout)  
**Explication** : Utilisation de `display: flex` et `justifyContent: 'space-around'` pour aligner les √©l√©ments du footer.

```python
style={'display': 'flex', 'justifyContent': 'space-around'}
```

#### 7. SQLAlchemy - ORM et connexion SQLite

**Fichier** : `db.py`, lignes 8-10  
**Source** : [Documentation SQLAlchemy](https://docs.sqlalchemy.org/en/20/core/engines.html)  
**Explication** : Cr√©ation d'un moteur SQLAlchemy pour se connecter √† SQLite. `create_engine()` avec le param√®tre `future=True` active le mode SQLAlchemy 2.0.

```python
from sqlalchemy import create_engine
engine = create_engine(DB_URL, future=True)
```

#### 8. Pandas - Lecture/√âcriture SQL

**Fichier** : `db.py`, lignes 18-20 et 26-28  
**Source** : [Pandas SQL Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html)  
**Explication** : Utilisation de `to_sql()` pour √©crire un DataFrame dans SQLite et `read_sql()` pour lire depuis une table SQL.

```python
df.to_sql(table, engine, if_exists="replace", index=False)
df = pd.read_sql(f"SELECT * FROM {table}", con=engine)
```

#### 9. Requests - T√©l√©chargement HTTP

**Fichier** : `src/utils/get_data.py`, lignes 20-25  
**Source** : [Documentation Requests](https://requests.readthedocs.io/)  
**Explication** : Utilisation de `requests.get()` pour t√©l√©charger un fichier depuis une URL et `response.content` pour r√©cup√©rer les donn√©es binaires.

```python
response = requests.get(DATA_URL)
with open(EXCEL_PATH, "wb") as f:
    f.write(response.content)
```

#### 10. Regex - Extraction de nombres

**Fichier** : `src/utils/clean_data.py`, lignes 20-25  
**Source** : [Python re module](https://docs.python.org/3/library/re.html)  
**Explication** : Expression r√©guli√®re `r"\d+(\.\d+)?"` pour extraire le premier nombre d√©cimal d'une cha√Æne. Utilis√© pour nettoyer les colonnes de notes.

```python
match = re.search(r"\d+(\.\d+)?", str(val))
if match:
    return float(match.group())
```

### D√©claration finale

**Toute ligne non d√©clar√©e ci-dessus est r√©put√©e √™tre produite par l'auteur (ou les auteurs) du projet.**

L'absence ou l'omission de d√©claration sera consid√©r√©e comme du plagiat.

**Auteurs** :
- OUCHAOU Lina
- POGEANT Justine

**Date** : Novembre 2025  
**Projet** : Dashboard √âgalit√© Professionnelle - Python 2025

---

<div align="center">

**Fait avec ‚ù§Ô∏è par OUCHAOU Lina & POGEANT Justine**

*Dashboard √âgalit√© Professionnelle 2025*

---

 Contact : [lina.ouchaou@edu.esiee.fr](lina.ouchaou@edu.esiee.fr) et [justine.pogeant@edu.esiee.fr](justine.pogeant@edu.esiee.fr)

 GitHub : [https://github.com/LinaOuchaouAmroussi/projet_data.git](https://github.com/LinaOuchaouAmroussi/projet_data.git)

</div>