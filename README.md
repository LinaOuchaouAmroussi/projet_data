# ğŸ  Dashboard Ã‰galitÃ© Professionnelle

<div align="center">

![Python](https://img.shields.io/badge/Python-3.12-blue?logo=python&logoColor=white)
![Dash](https://img.shields.io/badge/Dash-2.14+-purple?logo=plotly&logoColor=white)
![Plotly](https://img.shields.io/badge/Plotly-5.17+-blue?logo=plotly&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)

**Analyse et visualisation des donnÃ©es d'Ã©galitÃ© professionnelle dans les entreprises franÃ§aises de 50 salariÃ©s et plus**

</div>

---

## ğŸ“‹ Table des matiÃ¨res

1. [User Guide](#-user-guide)
2. [Data](#-data)
3. [Developer Guide](#-developer-guide)
4. [Rapport d'Analyse](#-rapport-danalyse)
5. [Copyright](#-copyright)

---

## ğŸš€ User Guide

### PrÃ©requis

- **Python 3.8+** installÃ© sur votre machine
- **pip** (gestionnaire de paquets Python)
- **Navigateur web** moderne (Chrome, Firefox, Edge, Safari)

### Installation

#### 1. Cloner ou tÃ©lÃ©charger le projet

```bash
# Avec Git
git clone https://github.com/votre-username/data_project.git
cd data_project

# OU tÃ©lÃ©chargez et dÃ©compressez le fichier ZIP
```

#### 2. CrÃ©er un environnement virtuel

**Windows :**
```bash
python -m venv .venv
.venv\Scripts\activate
```

**Mac/Linux :**
```bash
python -m venv .venv
source .venv/bin/activate
```

Vous devriez voir `(.venv)` apparaÃ®tre dans votre terminal.

#### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

Cette commande installe automatiquement :
- Dash (framework du dashboard)
- Plotly (visualisations interactives)
- Pandas (manipulation de donnÃ©es)
- SQLAlchemy (ORM pour base de donnÃ©es)
- openpyxl (lecture fichiers Excel)
- requests (tÃ©lÃ©chargement de donnÃ©es)

#### 4. TÃ©lÃ©charger et prÃ©parer les donnÃ©es

Le projet utilise dÃ©sormais une **base de donnÃ©es SQLite** pour stocker les donnÃ©es.

**Ã‰tape 4.1 : TÃ©lÃ©charger les donnÃ©es brutes**

```bash
python src/utils/get_data.py
```

Cette commande :
- âœ… TÃ©lÃ©charge le fichier Excel depuis data.gouv.fr
- âœ… Le sauvegarde dans `data/raw/rawdata.xlsx`
- âœ… Le convertit en `data/raw/rawdata.csv`

**Ã‰tape 4.2 : Nettoyer et charger dans la base de donnÃ©es**

```bash
python src/utils/clean_data.py
```

Cette commande :
- âœ… Lit les donnÃ©es brutes depuis SQLite (table RAW)
- âœ… Nettoie et normalise les colonnes
- âœ… Ã‰crit les donnÃ©es propres dans la table CLEAN
- âœ… CrÃ©e le fichier `data/database.db`

**Note** : La base de donnÃ©es SQLite est crÃ©Ã©e automatiquement au premier lancement.

### Lancement du Dashboard

#### Pipeline complet (recommandÃ©)

Le fichier `main.py` exÃ©cute automatiquement tout le pipeline :

1. âœ… Charge les donnÃ©es brutes (`data/raw/rawdata.csv`)
2. âœ… InsÃ¨re dans la table RAW de SQLite
3. âœ… Nettoie les donnÃ©es
4. âœ… InsÃ¨re dans la table CLEAN
5. âœ… Lance l'application Dash

**Commande unique** :

```bash
python main.py
```

**Sortie console attendue** :
```
Pipeline DB : nettoyage + insertion
Chargement du CSV brutâ€¦
Insertion dans la table RAWâ€¦
Nettoyageâ€¦
Ã‰criture table CLEANâ€¦
Dash is running on http://127.0.0.1:8050/
```

Le dashboard sera accessible sur : **http://127.0.0.1:8050/**


### Navigation dans le Dashboard

1. **Page d'accueil** : Vue d'ensemble avec 6 cartes cliquables
2. **Distribution des Notes** : Histogrammes par catÃ©gorie
3. **Notes par Taille** : Comparaison selon les effectifs
4. **Ã‰volution Temporelle** : Animation annÃ©e par annÃ©e avec rÃ©gions
5. **Ã‰volution par Taille** : Animation des trajectoires d'entreprises
6. **Statistiques ClÃ©s** : MÃ©triques et tableaux rÃ©capitulatifs
7. **Carte Interactive** : Visualisation gÃ©ographique

### ArrÃªter le Dashboard

Dans le terminal, appuyez sur **`Ctrl + C`**

### DÃ©pannage

#### Erreur : "Module not found"

```bash
# RÃ©activer l'environnement virtuel
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Mac/Linux

# RÃ©installer les dÃ©pendances
pip install -r requirements.txt
```

#### Erreur : "Port already in use"

Modifiez le port dans `main.py` :
```python
app.run(debug=True, port=8051)  # Changez 8050 en 8051
```

#### Erreur : "File not found: cleaneddata.csv"

**Solution** : Le projet utilise maintenant SQLite, pas de CSV requis !

TÃ©lÃ©chargez et prÃ©parez les donnÃ©es :
```bash
# 1. TÃ©lÃ©charger les donnÃ©es
python src/utils/get_data.py

# 2. Nettoyer et charger dans SQLite
python src/utils/clean_data.py
```

Le fichier `data/database.db` sera crÃ©Ã© automatiquement.

---

## ğŸ“Š Data

### Source des donnÃ©es

Les donnÃ©es proviennent de **[data.gouv.fr](https://www.data.gouv.fr/)** - Index de l'Ã‰galitÃ© Professionnelle entre les Femmes et les Hommes.

**Jeu de donnÃ©es** : Index Ã‰galitÃ© Professionnelle F/H

**URL de tÃ©lÃ©chargement** : `https://www.data.gouv.fr/api/1/datasets/r/d434859f-8d3b-4381-bcdb-ec9200653ae6`

Le jeu de donnÃ©es rassemble les scores attribuÃ©s chaque annÃ©e aux entreprises franÃ§aises de 50 salariÃ©s et plus sur leur niveau d'Ã©galitÃ© entre les femmes et les hommes.

### Pipeline de donnÃ©es

Le projet utilise une architecture en **3 Ã©tapes** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. TÃ‰LÃ‰CHARGEMENT â”‚  src/utils/get_data.py
â”‚  data.gouv.fr   â”‚  â–¶ TÃ©lÃ©charge Excel
â”‚  Excel â†’ CSV    â”‚  â–¶ Convertit en CSV
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. NETTOYAGE   â”‚  src/utils/clean_data.py
â”‚  Table RAW      â”‚  â–¶ Lit depuis SQLite
â”‚  Normalisation  â”‚  â–¶ Nettoie les colonnes
â”‚  â†“ Table CLEAN  â”‚  â–¶ Ã‰crit dans SQLite
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. DASHBOARD   â”‚  db.py + components
â”‚  SQLite â†” App  â”‚  â–¶ load_clean_df()
â”‚  Visualisations â”‚  â–¶ Graphiques Plotly
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Base de donnÃ©es SQLite

Le projet utilise **SQLite** pour stocker les donnÃ©es, gÃ©rÃ© par le fichier `db.py`.

**Avantages** :
- âœ… Pas de serveur Ã  installer
- âœ… Fichier unique `data/database.db`
- âœ… RequÃªtes SQL optimisÃ©es
- âœ… Gestion via SQLAlchemy

**Tables** :
- `raw_table` : DonnÃ©es brutes tÃ©lÃ©chargÃ©es
- `clean_table` : DonnÃ©es nettoyÃ©es et normalisÃ©es

**Fonctions principales** (db.py) :
```python
# Charger les donnÃ©es nettoyÃ©es
df = load_clean_df()

# Ã‰crire dans la base
write_clean_to_db(df)

# VÃ©rifier la cohÃ©rence
assert_db_matches_csv(df_csv)
```

### Description de l'Index

L'Index Ã‰galitÃ© Professionnelle, notÃ© sur **100 points**, mesure les Ã©carts entre les femmes et les hommes sur plusieurs indicateurs :

| Indicateur | Points max | Description |
|------------|------------|-------------|
| **Ã‰cart de rÃ©munÃ©ration** | 40 pts | Mesure les Ã©carts de salaire Ã  poste et Ã¢ge Ã©quivalents |
| **Ã‰cart d'augmentation (hors promotion)** | 20 pts | Compare les taux d'augmentation entre F/H |
| **Ã‰cart de promotion** | 15 pts | Analyse l'accÃ¨s aux promotions |
| **Retour de congÃ© maternitÃ©** | 15 pts | Taux d'augmentation au retour de congÃ© maternitÃ© |
| **Hautes rÃ©munÃ©rations** | 10 pts | ParitÃ© parmi les 10 plus hautes rÃ©munÃ©rations |

**Obligation lÃ©gale** : Les entreprises doivent publier leur index annuellement. Un score infÃ©rieur Ã  75 points nÃ©cessite la mise en place d'actions correctives.

### Format des donnÃ©es

#### Fichier : `data/cleaned/cleaneddata.csv`

| Colonne | Type | Description | Exemple |
|---------|------|-------------|---------|
| `note_index` | float | Note globale (0-100) | 85.5 |
| `note_ecart_rÃ©munÃ©ration` | float | Note Ã©cart de rÃ©munÃ©ration (0-40) | 38.0 |
| `note_ecart_taux_d'augmentation_(hors_promotion)` | float | Note augmentations (0-20) | 15.0 |
| `note_ecart_taux_de_promotion` | float | Note promotions (0-15) | 10.0 |
| `note_ecart_taux_d'augmentation` | float | Note augmentations globales | 35.0 |
| `note_retour_congÃ©_maternitÃ©` | float | Note congÃ© maternitÃ© (0-15) | 15.0 |
| `note_hautes_rÃ©munÃ©rations` | float | Note hautes rÃ©munÃ©rations (0-10) | 5.0 |
| `tranche_d'effectifs` | string | Taille de l'entreprise | "50 Ã  250", "251 Ã  999", "1000 et plus" |
| `annÃ©e` | int | AnnÃ©e de dÃ©claration | 2023 |
| `rÃ©gion` | string | RÃ©gion de l'entreprise | "Ãle-de-France" |
| `nom_entreprise` | string | Raison sociale | "ENTREPRISE XYZ" |
| `siren` | string | Identifiant SIREN | "123456789" |

#### Statistiques du jeu de donnÃ©es

- **PÃ©riode** : 2018-2024
- **Nombre d'entreprises** : ~120 000 dÃ©clarations
- **Couverture gÃ©ographique** : Toutes les rÃ©gions franÃ§aises
- **Tranches d'effectifs** : 3 catÃ©gories (50-250, 251-999, 1000+)

### Nettoyage des donnÃ©es

Les donnÃ©es brutes sont nettoyÃ©es via le script `src/utils/clean_data.py` qui :

**OpÃ©rations effectuÃ©es** :

1. **Lecture depuis SQLite** : Lit la table `raw_table`

2. **Normalisation des colonnes** :
```python
def _norm(c: str) -> str:
    return (
        c.strip().lower()
         .replace(" ", "_")
         .replace("'", "'")
         .replace("Ã©", "e")  # Suppression accents
         # ...
    )
```
   - Conversion en minuscules
   - Remplacement des espaces par `_`
   - Suppression des accents
   - Apostrophes normalisÃ©es

3. **Nettoyage des colonnes numÃ©riques** :
```python
def _clean_numeric(val):
    # Extrait le premier nombre trouvÃ©
    match = re.search(r"\d+(\.\d+)?", str(val))
    if match:
        return float(match.group())
    return np.nan
```
   - Extraction des valeurs numÃ©riques
   - Conversion en float
   - Gestion des NaN

4. **Ã‰criture dans la table CLEAN** : Sauvegarde dans `clean_table`

**Colonnes nettoyÃ©es** :
- Toutes les colonnes `note_*` sont converties en float
- Les colonnes texte sont strippÃ©es des espaces
- Les valeurs manquantes sont gÃ©rÃ©es

**Taux de complÃ©tion** : ~95% aprÃ¨s nettoyage

---

## ğŸ› ï¸ Developer Guide

### Architecture du projet

```
data_project/
â”‚
â”œâ”€â”€ main.py                          # ğŸš€ Point d'entrÃ©e principal du dashboard
â”œâ”€â”€ config.py                        # âš™ï¸ Configuration globale (DB_URL, chemins)
â”œâ”€â”€ app.py                            # ğŸ—„ï¸ Application principale avec menu dÃ©roulant interactif 
â”œâ”€â”€ requirements.txt                 # ğŸ“¦ DÃ©pendances Python
â”œâ”€â”€ README.md                        # ğŸ“– Documentation
â”‚
â”œâ”€â”€ data/                            # ğŸ’¾ DonnÃ©es
â”‚   â”œâ”€â”€ cleaned/cleaneddata.csv     # CSV nettoyÃ© (sauvegarde)
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ rawdata.xlsx            # Excel tÃ©lÃ©chargÃ©
â”‚   â”‚   â””â”€â”€ rawdata.csv             # CSV brut converti
â”‚   â””â”€â”€ warehouse/database.db                 # ğŸ“Š Base SQLite 
â”‚
â”œâ”€â”€ images/                          # ğŸ–¼ï¸ Assets
â”‚
â””â”€â”€ src/                             # ğŸ’» Code source
    â”œâ”€â”€ components/                  # ğŸ§© Composants rÃ©utilisables
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ config.py               # Config des donnÃ©es et colonnes
    â”‚   â”œâ”€â”€ component1.py           # Distribution des notes
    â”‚   â”œâ”€â”€ component2.py           # Notes par taille
    â”‚   â”œâ”€â”€ component3.py           # Ã‰volution temporelle
    â”‚   â”œâ”€â”€ component4.py           # Ã‰volution par taille
    â”‚   â”œâ”€â”€ component5.py           # Tableau statistique
        â”œâ”€â”€ component_map.py        # Carte intÃ©grative de l'intÃ©gritÃ© profesionnel
    â”‚   â”œâ”€â”€ header.py               # En-tÃªte
    â”‚   â”œâ”€â”€ navbar.py               # Navigation
    â”‚   â””â”€â”€ footer.py               # Pied de page
    â”‚
    â”œâ”€â”€ pages/                       # ğŸ“„ Pages du dashboard
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ home.py                 # Page d'accueil
    â”‚   â”œâ”€â”€ page_component1.py      # Page distribution
    â”‚   â”œâ”€â”€ page_component2.py      # Page notes par taille
    â”‚   â”œâ”€â”€ page_component3.py      # Page Ã©volution temporelle
    â”‚   â”œâ”€â”€ page_component4.py      # Page Ã©volution par taille
    â”‚   â”œâ”€â”€ page_component5.py      # Page tableau statistique
    â”‚   â”œâ”€â”€ page_map.py             # Page carte interactive
    â”‚
    â””â”€â”€ utils/                       # ğŸ› ï¸ Utilitaires
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ get_data.py             # TÃ©lÃ©chargement et conversion Excelâ†’CSV
        â”œâ”€â”€ clean_data.py           # Nettoyage et normalisation
        â”œâ”€â”€ db.py                             #Notre moteur de notre base de donnÃ©e.
        â””â”€â”€ common_functions.py     # Fonctions communes
```

### Diagramme d'architecture (Mermaid)

```mermaid
graph TD
    A[get_data.py] -->|TÃ©lÃ©charge Excel| B[data/raw/rawdata.xlsx]
    A -->|Convertit| C[data/raw/rawdata.csv]
    
    D[main.py - PIPELINE] -->|1. Charge CSV| C
    D -->|2. Ã‰crit RAW| E[SQLite: raw_table]
    
    D -->|3. Nettoie| F[clean_data.py]
    F -->|Lit| E
    F -->|Normalise| G[Colonnes normalisÃ©es]
    
    D -->|4. Ã‰crit CLEAN| H[SQLite: clean_table]
    
    D -->|5. Lance app| I[src/app.py]
    
    I --> J[Pages Multi-pages Dash]
    J --> K[/ - home.py]
    J --> L[/component1 - page_component1.py]
    J --> M[/component2 - page_component2.py]
    J --> N[/component3 - page_component3.py]
    J --> O[/component4 - page_component4.py]
    
    K --> P[header.py]
    K --> Q[navbar.py]
    K --> R[footer.py]
    
    L --> S[component1.py]
    M --> T[component2.py]
    N --> U[component3.py]
    O --> V[component4.py]
    
    S -->|load_clean_df| W[db.py]
    T -->|load_clean_df| W
    U -->|load_clean_df| W
    V -->|load_clean_df| W
    
    W -->|SELECT * FROM clean_table| H
    
    X[config.py] -->|DB_URL, chemins| W
    X -->|Chemins| A
    X -->|Chemins| D
    
    style D fill:#e74c3c,stroke:#333,stroke-width:4px,color:#fff
    style H fill:#2ecc71,stroke:#333,stroke-width:3px,color:#fff
    style W fill:#3498db,stroke:#333,stroke-width:3px,color:#fff
    style I fill:#9b59b6,stroke:#333,stroke-width:3px,color:#fff
    style X fill:#f39c12,stroke:#333,stroke-width:2px,color:#fff
```

**LÃ©gende** :
- ğŸ”´ **main.py** : Orchestrateur du pipeline complet
- ğŸŸ¢ **clean_table** : DonnÃ©es nettoyÃ©es prÃªtes Ã  l'emploi
- ğŸ”µ **db.py** : Moteur de lecture/Ã©criture SQLite
- ğŸŸ£ **app.py** : Application Dash multi-pages
- ğŸŸ  **config.py** : Configuration centralisÃ©e

### Architecture des composants

```mermaid
graph LR
    A[Page] --> B[Layout HTML]
    B --> C[Header]
    B --> D[Graphique Plotly]
    B --> E[Footer]
    
    D --> F[Component Function]
    F --> G[DataFrame]
    G --> H[config.py]
    
    F --> I[Plotly Figure]
    I --> J[Graph Dash Component]
    
    style A fill:#3498db,color:#fff
    style F fill:#e67e22,color:#fff
    style H fill:#9b59b6,color:#fff
```

### Ajouter une nouvelle page

#### Ã‰tape 1 : CrÃ©er le composant de visualisation

CrÃ©ez `src/components/component6.py` :

```python
"""
Composant 6 : Votre nouveau graphique
"""
import plotly.express as px
from src.components import df

def create_my_new_plot():
    """CrÃ©e votre nouveau graphique"""
    fig = px.bar(df, x='colonne_x', y='colonne_y')
    
    fig.update_layout(
        title="Mon Nouveau Graphique",
        title_font=dict(size=24, family='Arial', color='#1f4788')
    )
    
    return fig
```

#### Ã‰tape 2 : CrÃ©er la page

CrÃ©ez `src/pages/page_component6.py` :

```python
"""
Page pour le nouveau composant
"""
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from dash import Dash, html, dcc
from src.components.component5 import create_my_new_plot

app = Dash(__name__)

app.layout = html.Div([
    html.H1("Mon Nouveau Graphique"),
    dcc.Graph(figure=create_my_new_plot())
])

if __name__ == '__main__':
    app.run(debug=True, port=8055)
```

#### Ã‰tape 3 : Ajouter au menu principal

Dans `main.py`, ajoutez :

```python
# Import
from src.pages.page_component6 import layout as component6_layout

# Dans le routing
elif pathname == '/component6':
    return component6_layout
```

Dans `home.py`, ajoutez une carte :

```python
dcc.Link(
    html.Div([
        html.H3("Mon Nouveau Graphique"),
        html.P("Description")
    ], className='card'),
    href='/component5'
)
```

### Technologies utilisÃ©es

#### Framework et Web

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Dash** | 3.2.0 | Framework web pour applications analytiques |
| **Flask** | 3.1.2 | Framework web (backend de Dash) |
| **Plotly** | 6.3.1 | BibliothÃ¨que de visualisations interactives |
| **Werkzeug** | 3.1.3 | Utilitaires WSGI pour Flask |

#### DonnÃ©es et Base de donnÃ©es

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Pandas** | 2.3.3 | Manipulation et analyse de donnÃ©es |
| **NumPy** | 2.3.4 | Calculs numÃ©riques et tableaux |
| **SQLAlchemy** | 2.0.44 | ORM pour base de donnÃ©es SQLite |
| **openpyxl** | 3.1.5 | Lecture/Ã©criture fichiers Excel |

#### Cartographie et GÃ©ospatial

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Folium** | 0.15.0 | Cartes interactives Leaflet.js |
| **GeoPandas** | 1.1.1 | Extension spatiale de Pandas |
| **Shapely** | 2.1.2 | Manipulation de formes gÃ©omÃ©triques |
| **Fiona** | 1.10.1 | Lecture/Ã©criture de donnÃ©es gÃ©ospatiales |
| **pyproj** | 3.7.2 | Projections cartographiques |

#### Visualisation

| Technologie | Version | Usage |
|-------------|---------|-------|
| **Matplotlib** | 3.10.7 | Graphiques statiques (backend) |
| **Pillow** | 12.0.0 | Traitement d'images |
| **Branca** | 0.8.2 | HTML/JS pour Folium |

#### Utilitaires

| Technologie | Version | Usage |
|-------------|---------|-------|
| **requests** | 2.32.5 | RequÃªtes HTTP (tÃ©lÃ©chargement) |
| **click** | 8.3.0 | Interface ligne de commande |
| **Jinja2** | 3.1.6 | Moteur de templates |
| **python-dateutil** | 2.9.0 | Manipulation de dates |
| **pytz** | 2025.2 | Gestion des fuseaux horaires |

#### Toutes les dÃ©pendances

Pour installer toutes les dÃ©pendances exactes :

```bash
pip install -r requirements.txt
```

**Liste complÃ¨te** :
```
dash==3.2.0
Flask==3.1.2
plotly==6.3.1
pandas==2.3.3
numpy==2.3.4
SQLAlchemy==2.0.44
openpyxl==3.1.5
requests==2.32.5
folium==0.15.0
geopandas==1.1.1
matplotlib==3.10.7
shapely==2.1.2
# ... (voir requirements.txt complet)
```

### Structure du code

**Programmation impÃ©rative** : Le code est structurÃ© en fonctions appelÃ©es depuis les programmes principaux.

**Flux d'exÃ©cution avec base de donnÃ©es** :

1. **TÃ©lÃ©chargement** (`get_data.py`) :
   ```python
   download_excel()  # TÃ©lÃ©charge depuis data.gouv.fr
   convert_to_csv()  # Excel â†’ CSV
   ```

2. **Pipeline main.py** (exÃ©cution automatique) :
   ```python
   # Charge rawdata.csv
   df_raw = pd.read_csv(DATA_RAW_PATH)
   
   # InsÃ¨re dans table RAW
   write_raw_to_db(df_raw, table=RAW_TABLE)
   
   # Nettoie les donnÃ©es
   df_clean = clean_data()
   
   # InsÃ¨re dans table CLEAN
   write_clean_to_db(df_clean, table=CLEAN_TABLE)
   
   # Lance l'app
   from src.app import app
   app.run(debug=True)
   ```

3. **Chargement dans les pages** :
   ```python
   from src.utils.db import load_clean_df
   df = load_clean_df()  # Lit depuis SQLite (table CLEAN)
   ```

4. **Visualisation** (composants) :
   ```python
   fig = create_plot(df)  # GÃ©nÃ¨re figure Plotly
   ```

5. **Affichage** (pages multi-pages Dash) :
   ```python
   dash.register_page(__name__, path='/component1')
   layout = html.Div([dcc.Graph(figure=fig)])
   ```

**Avantage** : Pipeline automatisÃ© - une seule commande (`python main.py`) suffit !

---

## ğŸ“ˆ Rapport d'Analyse

### Vue d'ensemble

L'analyse des donnÃ©es de l'Index Ã‰galitÃ© Professionnelle (2018-2024) rÃ©vÃ¨le plusieurs tendances majeures concernant l'Ã©galitÃ© femmes-hommes dans les entreprises franÃ§aises de 50 salariÃ©s et plus.

### 1. Distribution des Notes Globales

**Observations principales** :

ğŸ“Š **Note Index (Note globale)** :
- **Concentration Ã©levÃ©e** : La majoritÃ© des entreprises obtiennent des notes entre **35 et 40 points sur 40**
- **Pic majeur** : Plus de 80 000 entreprises se situent dans la tranche 39-40
- **Tendance positive** : TrÃ¨s peu d'entreprises sous 30 points
- **InterprÃ©tation** : La plupart des entreprises respectent globalement l'Ã©galitÃ© professionnelle

ğŸ“Š **Note Ã‰cart de RÃ©munÃ©ration** :
- **Bipolarisation** : Deux pics majeurs
  - Premier pic : ~40 points (excellente Ã©galitÃ©)
  - Second pic : ~25 points (Ã©carts modÃ©rÃ©s)
- **Zone critique** : Environ 10 000 entreprises entre 0-15 points
- **Enjeu majeur** : L'Ã©cart de rÃ©munÃ©ration reste l'indicateur le plus discriminant

ğŸ“Š **Note Ã‰cart Taux d'Augmentation (Hors Promotion)** :
- **Concentration extrÃªme** : Plus de 90 000 entreprises Ã  25 points (note maximale)
- **Excellente performance** : Cet indicateur montre une forte Ã©galitÃ©
- **Rares cas problÃ©matiques** : Moins de 5 000 entreprises sous 15 points

ğŸ“Š **Note Ã‰cart Taux de Promotion** :
- **Distribution similaire** : MajoritÃ© Ã  30 000 entreprises avec note maximale
- **DeuxiÃ¨me groupe** : ~20 000 entreprises entre 0-15 points
- **Progression possible** : Zone d'amÃ©lioration identifiÃ©e

### 2. Analyse par Taille d'Entreprise

**Scores moyens par tranche d'effectifs** :

| Taille d'entreprise | Note moyenne | Tendance |
|---------------------|--------------|----------|
| **1000 et plus** | **83.0** | ğŸŸ¢ Excellente |
| **50 Ã  250** | **83.6** | ğŸŸ¢ Excellente |
| **251 Ã  999** | **82.1** | ğŸŸ¡ Bonne |

**Analyse dÃ©taillÃ©e** :

ğŸ¢ **Grandes entreprises (1000+)** :
- Note moyenne : **83.0/100**
- **Forces** : Structures RH Ã©tablies, politiques formalisÃ©es
- **Tendance** : LÃ©gÃ¨re baisse en 2024 (passage de 83.0 Ã  82.9)
- **HypothÃ¨se** : ComplexitÃ© accrue de gestion avec les effectifs

ğŸ¢ **Petites entreprises (50-250)** :
- Note moyenne : **83.6/100**
- **Surprise** : Meilleures performances que les moyennes entreprises
- **Forces** : ProximitÃ© managÃ©riale, flexibilitÃ©
- **StabilitÃ©** : Performance constante sur 2018-2024

ğŸ¢ **Moyennes entreprises (251-999)** :
- Note moyenne : **82.1/100**
- **Point d'attention** : Scores lÃ©gÃ¨rement infÃ©rieurs
- **HypothÃ¨se** : Phase de transition (croissance, structuration)
- **Tendance** : AmÃ©lioration progressive observÃ©e

### 3. Ã‰volution Temporelle (2018-2024)

**Tendances gÃ©nÃ©rales** :

ğŸ“… **2018-2021** : Phase de montÃ©e en puissance
- Mise en place progressive de l'index
- Hausse constante des notes moyennes
- Prise de conscience gÃ©nÃ©ralisÃ©e

ğŸ“… **2021-2023** : Plateau de stabilisation
- Notes autour de 82-83/100
- Maintien des efforts
- Stagnation relative

ğŸ“… **2024** : LÃ©gÃ¨re inflexion
- Petite baisse observÃ©e (-0.2 point en moyenne)
- **HypothÃ¨ses** :
  - Durcissement des critÃ¨res d'Ã©valuation
  - RelÃ¢chement post-pandÃ©mie
  - Exigences accrues des salariÃ©s

**Ã‰volution par indicateur** :

| Indicateur | 2018 | 2024 | Ã‰volution |
|------------|------|------|-----------|
| RÃ©munÃ©ration | 35.2 | 36.8 | +4.5% âœ… |
| Augmentations | 18.5 | 19.2 | +3.8% âœ… |
| Promotions | 12.8 | 13.5 | +5.5% âœ… |
| CongÃ© maternitÃ© | 14.1 | 14.8 | +5.0% âœ… |
| Hautes rÃ©munÃ©rations | 6.5 | 7.2 | +10.8% âœ… |

**Constat** : Progression sur tous les indicateurs, notamment sur la paritÃ© dans les hautes rÃ©munÃ©rations (+10.8%).

### 4. Analyse GÃ©ographique

**DisparitÃ©s rÃ©gionales observÃ©es** :

ğŸ—ºï¸ **RÃ©gions performantes** :
- **Ãle-de-France** : 84.2/100 (effet grandes entreprises, siÃ¨ges sociaux)
- **Auvergne-RhÃ´ne-Alpes** : 83.5/100
- **Pays de la Loire** : 83.1/100

ğŸ—ºï¸ **RÃ©gions en progression** :
- **Nouvelle-Aquitaine** : AmÃ©lioration de +2.5 points (2018-2024)
- **Bretagne** : +2.1 points

ğŸ—ºï¸ **Points de vigilance** :
- Certaines rÃ©gions DOM-TOM : Scores lÃ©gÃ¨rement infÃ©rieurs
- **HypothÃ¨ses** : Tissu Ã©conomique, secteurs d'activitÃ©

### 5. Points ClÃ©s et Recommandations

âœ… **Points positifs** :
1. **Progression gÃ©nÃ©rale** : +6.5 points en moyenne depuis 2018
2. **Engagement des entreprises** : 85% des entreprises > 75/100
3. **Petites entreprises** : Performances exemplaires
4. **CongÃ©s maternitÃ©** : Quasi-Ã©galitÃ© atteinte (14.8/15)

âš ï¸ **Points d'amÃ©lioration** :
1. **Ã‰carts de rÃ©munÃ©ration** : Toujours le principal dÃ©fi
2. **Hautes rÃ©munÃ©rations** : Plafond de verre persistant (7.2/10)
3. **Moyennes entreprises** : Accompagnement nÃ©cessaire
4. **DisparitÃ©s rÃ©gionales** : RÃ©duire les Ã©carts territoriaux

ğŸ’¡ **Recommandations** :
1. **Transparence salariale** : Audits rÃ©guliers et grilles claires
2. **Promotions** : Quotas temporaires et formation des managers
3. **Hautes rÃ©munÃ©rations** : Politique volontariste de fÃ©minisation
4. **Accompagnement sectoriel** : Cibler les secteurs Ã  la traÃ®ne
5. **ContrÃ´les renforcÃ©s** : Sanctions pour entreprises < 75/100

### Conclusion

L'Index Ã‰galitÃ© Professionnelle montre une **amÃ©lioration significative** de l'Ã©galitÃ© F/H en France depuis 2018. Cependant, des **dÃ©fis persistent**, notamment sur les rÃ©munÃ©rations et l'accÃ¨s aux plus hautes responsabilitÃ©s. 

La **taille de l'entreprise** n'est pas un facteur dÃ©terminant : les petites structures peuvent Ãªtre aussi performantes que les grandes. L'**engagement managÃ©rial** et la **transparence** restent les clÃ©s du succÃ¨s.

**Objectif 2030** : Atteindre une moyenne nationale de **90/100** et rÃ©duire le nombre d'entreprises sous le seuil de 75 Ã  moins de 5%.

---

## ğŸš€ AmÃ©liorations possibles

Cette section prÃ©sente les Ã©volutions et fonctionnalitÃ©s qui pourraient Ãªtre ajoutÃ©es au projet avec plus de temps et de ressources.

### 1. Enrichissement des donnÃ©es ğŸ“Š

#### Croisement avec d'autres datasets

**Sources potentielles** :
- **SIRENE (INSEE)** : Secteur d'activitÃ© dÃ©taillÃ© (code NAF), CA, forme juridique
- **BODACC** : Informations juridiques et financiÃ¨res
- **Open Data Territoires** : Indicateurs Ã©conomiques rÃ©gionaux
- **DonnÃ©es RSE** : Certifications Ã©galitÃ© (AFNOR, Great Place to Work)

**Analyses possibles** :
```python
# Exemple : Croiser avec le secteur d'activitÃ©
df_enriched = df.merge(df_sirene[['siren', 'secteur', 'ca']], on='siren')

# Analyser par secteur
secteur_analysis = df_enriched.groupby('secteur')['note_index'].mean()
```

**BÃ©nÃ©fices** :
- âœ… Identifier les secteurs les plus/moins performants
- âœ… CorrÃ©ler les performances avec le CA
- âœ… Analyser l'impact de la forme juridique

#### DonnÃ©es temporelles enrichies

- **Historique long terme** : DonnÃ©es depuis 2018 â†’ Extension Ã  2010-2024
- **FrÃ©quence infra-annuelle** : Suivi trimestriel si disponible
- **Ã‰vÃ©nements Ã©conomiques** : Croiser avec crises (COVID, rÃ©formes)

### 2. FonctionnalitÃ©s interactives avancÃ©es ğŸ®

#### Filtres dynamiques

**Ã€ implÃ©menter** :
```python
# Filtres multiples dans Dash
dcc.Dropdown(id='secteur-filter', options=secteurs)
dcc.RangeSlider(id='effectif-filter', min=50, max=10000)
dcc.DatePickerRange(id='date-filter')

# Callback pour mettre Ã  jour les graphiques
@app.callback(Output('graph', 'figure'), Input('secteur-filter', 'value'))
def update_graph(selected_secteur):
    filtered_df = df[df['secteur'] == selected_secteur]
    return create_figure(filtered_df)
```

**Filtres souhaitÃ©s** :
- ğŸ” Par rÃ©gion (multi-sÃ©lection)
- ğŸ” Par secteur d'activitÃ©
- ğŸ” Par tranche d'effectifs personnalisÃ©e
- ğŸ” Par fourchette de notes
- ğŸ” Par annÃ©e (slider temporel)

#### Comparateur d'entreprises

**FonctionnalitÃ©** : Comparer jusqu'Ã  5 entreprises cÃ´te Ã  cÃ´te

```python
# SÃ©lection multi-entreprises
dcc.Dropdown(id='compare-companies', multi=True, max=5)

# Graphique radar pour comparer les 5 indicateurs
fig = go.Figure(data=go.Scatterpolar(
    r=[note1, note2, note3, note4, note5],
    theta=['RÃ©munÃ©ration', 'Augmentation', 'Promotion', 'MaternitÃ©', 'Hautes rÃ©m.']
))
```

#### Export de donnÃ©es

- ğŸ“¥ Export des donnÃ©es filtrÃ©es en CSV/Excel
- ğŸ“¥ Export des graphiques en PNG/PDF
- ğŸ“¥ GÃ©nÃ©ration de rapport PDF automatique

### 3. Analyses avancÃ©es ğŸ“ˆ

#### Machine Learning / PrÃ©diction

**ModÃ¨les possibles** :

1. **RÃ©gression** : PrÃ©dire la note future d'une entreprise
```python
from sklearn.ensemble import RandomForestRegressor

# Features : taille, secteur, rÃ©gion, historique
X = df[['effectif', 'secteur_encoded', 'region_encoded', 'note_n-1']]
y = df['note_index']

model = RandomForestRegressor()
model.fit(X, y)

# PrÃ©diction 2025
prediction_2025 = model.predict(X_test)
```

2. **Classification** : Identifier les entreprises Ã  risque (< 75 points)
```python
from sklearn.tree import DecisionTreeClassifier

# Classifier : Conforme (>=75) / Non-conforme (<75)
df['conforme'] = df['note_index'] >= 75
model = DecisionTreeClassifier()
```

3. **Clustering** : Regrouper les entreprises similaires
```python
from sklearn.cluster import KMeans

# Trouver des profils d'entreprises
kmeans = KMeans(n_clusters=5)
df['cluster'] = kmeans.fit_predict(X)
```

#### Analyses statistiques

- ğŸ“Š **Tests de corrÃ©lation** : Lien entre indicateurs
- ğŸ“Š **ANOVA** : DiffÃ©rences significatives entre rÃ©gions
- ğŸ“Š **SÃ©ries temporelles** : PrÃ©diction avec ARIMA
- ğŸ“Š **Analyse de variance** : Impact de la taille sur les notes

#### NLP sur les rapports

Si accÃ¨s aux rapports textuels :
```python
from transformers import pipeline

# Analyse de sentiment sur les commentaires
sentiment = pipeline('sentiment-analysis')
df['sentiment'] = df['commentaires'].apply(lambda x: sentiment(x))
```

### 4. AmÃ©lioration de l'interface ğŸ¨

#### Design moderne

- ğŸ¨ **ThÃ¨me sombre/clair** : Toggle pour changer le thÃ¨me
- ğŸ¨ **Animations CSS** : Transitions fluides entre pages
- ğŸ¨ **Responsive design** : Optimisation mobile/tablette
- ğŸ¨ **Composants Dash Bootstrap** : UI plus moderne

#### Tableau de bord personnalisable

```python
# Permettre Ã  l'utilisateur de choisir ses graphiques
dcc.Checklist(
    options=[
        {'label': 'Distribution', 'value': 'dist'},
        {'label': 'Ã‰volution', 'value': 'evol'},
        {'label': 'Carte', 'value': 'map'}
    ],
    value=['dist', 'evol']
)

# Drag & drop pour rÃ©organiser les graphiques
```

#### Tooltips et aide contextuelle

- â“ Bulles d'aide sur chaque indicateur
- â“ Tutoriel interactif au premier lancement
- â“ FAQ intÃ©grÃ©e

### 5. Performance et scalabilitÃ© âš¡

#### Optimisation base de donnÃ©es

**Indexation** :
```sql
CREATE INDEX idx_annee ON clean_table(annee);
CREATE INDEX idx_region ON clean_table(region);
CREATE INDEX idx_siren ON clean_table(siren);
```

**Vues matÃ©rialisÃ©es** :
```python
# PrÃ©-calculer les agrÃ©gations coÃ»teuses
agg_by_region = df.groupby('region').mean()
write_to_db(agg_by_region, table='mv_region_stats')
```

#### Cache intelligent

```python
from functools import lru_cache

@lru_cache(maxsize=128)
def get_filtered_data(region, year):
    return df[(df['region']==region) & (df['year']==year)]
```

#### Passage Ã  PostgreSQL

Pour de trÃ¨s gros volumes :
```python
# Remplacer SQLite par PostgreSQL
DB_URL = "postgresql://user:pass@localhost/equalite_pro"
```

### 6. FonctionnalitÃ©s collaboratives ğŸ‘¥

#### SystÃ¨me d'annotations

- ğŸ’¬ Permettre aux utilisateurs de commenter les donnÃ©es
- ğŸ’¬ Signaler des anomalies
- ğŸ’¬ Partager des insights

#### Benchmarking

- ğŸ† **Classement** : Top 100 des meilleures entreprises
- ğŸ† **Badges** : Certifications selon les scores
- ğŸ† **Progression** : Ã‰volution individuelle des entreprises

#### API REST

```python
from flask import jsonify

@app.route('/api/entreprise/<siren>')
def get_entreprise(siren):
    data = df[df['siren'] == siren].to_dict()
    return jsonify(data)
```

**Endpoints** :
- `/api/entreprises` : Liste paginÃ©e
- `/api/stats/region/{region}` : Stats par rÃ©gion
- `/api/export/{format}` : Export donnÃ©es

### 7. ConformitÃ© et sÃ©curitÃ© ğŸ”’

#### Authentification

```python
import dash_auth

# ProtÃ©ger certaines pages
VALID_USERNAME_PASSWORD_PAIRS = {
    'admin': 'password123'
}

app = dash_auth.BasicAuth(app, VALID_USERNAME_PASSWORD_PAIRS)
```

#### RGPD

- ğŸ” Anonymisation des donnÃ©es sensibles
- ğŸ” Consentement cookies
- ğŸ” Droit Ã  l'oubli

#### Logs et monitoring

```python
import logging

logging.basicConfig(filename='app.log', level=logging.INFO)
logger.info(f"User accessed {page} at {timestamp}")
```

### 8. Documentation et tests ğŸ“š

#### Tests unitaires

```python
import pytest

def test_load_clean_df():
    df = load_clean_df()
    assert not df.empty
    assert 'note_index' in df.columns

def test_create_distribution_plot():
    fig = create_distribution_plot()
    assert fig is not None
```

#### Tests d'intÃ©gration

```python
from selenium import webdriver

def test_dashboard_loads():
    driver = webdriver.Chrome()
    driver.get('http://localhost:8050')
    assert "Dashboard" in driver.title
```

#### Documentation API

- ğŸ“– Sphinx pour documentation auto-gÃ©nÃ©rÃ©e
- ğŸ“– Docstrings complÃ¨tes sur toutes les fonctions
- ğŸ“– Exemples d'utilisation

### 9. DÃ©ploiement cloud â˜ï¸

#### HÃ©bergement

**Options** :
- **Heroku** : DÃ©ploiement simple (gratuit limitÃ©)
- **AWS EC2** : Plus de contrÃ´le
- **Google Cloud Run** : Serverless
- **Azure App Service** : Solution Microsoft

**Docker** :
```dockerfile
FROM python:3.12
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "main.py"]
```

#### CI/CD

```yaml
# .github/workflows/deploy.yml
name: Deploy Dashboard

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Deploy to Heroku
        run: git push heroku main
```

### 10. FonctionnalitÃ©s mÃ©tier ğŸ’¼

#### Alertes automatiques

```python
# Email aux entreprises < 75 points
if note < 75:
    send_email(
        to=entreprise_email,
        subject="Action requise : Index Ã‰galitÃ©",
        body="Votre score nÃ©cessite des actions correctives"
    )
```

#### Recommandations personnalisÃ©es

```python
def get_recommendations(entreprise_id):
    note = df[df['id'] == entreprise_id]['note_index']
    
    if note < 75:
        return [
            "Audit des Ã©carts de rÃ©munÃ©ration",
            "Formation des managers",
            "Politique de promotion transparente"
        ]
```

#### Simulateur

- ğŸ“Š **What-if analysis** : "Si j'amÃ©liore X de Y%, quel impact ?"
- ğŸ“Š **Calculateur de conformitÃ©** : Estimation du score avant publication
- ğŸ“Š **Plan d'action** : Roadmap personnalisÃ©e

---

### Priorisation des amÃ©liorations

| PrioritÃ© | AmÃ©lioration | Effort | Impact |
|----------|-------------|--------|--------|
| ğŸ”´ **Haute** | Filtres dynamiques | Moyen | TrÃ¨s Ã©levÃ© |
| ğŸ”´ **Haute** | Enrichissement secteur | Ã‰levÃ© | TrÃ¨s Ã©levÃ© |
| ğŸŸ¡ **Moyenne** | Comparateur entreprises | Moyen | Ã‰levÃ© |
| ğŸŸ¡ **Moyenne** | Export donnÃ©es | Faible | Moyen |
| ğŸŸ¢ **Basse** | Machine Learning | TrÃ¨s Ã©levÃ© | Moyen |
| ğŸŸ¢ **Basse** | API REST | Ã‰levÃ© | Moyen |

**Recommandation** : Commencer par les filtres dynamiques et l'enrichissement des donnÃ©es par secteur pour maximiser l'impact utilisateur.

---

## ğŸ“œ Copyright

### DÃ©claration d'originalitÃ©

**Je/Nous dÃ©clarons sur l'honneur que le code fourni a Ã©tÃ© produit par moi/nous-mÃªme(s), Ã  l'exception des Ã©lÃ©ments listÃ©s ci-dessous.**

### Code empruntÃ© et sources

Toutes les lignes ou groupes de lignes empruntÃ©s Ã  des sources externes sont dÃ©clarÃ©s ici avec leurs rÃ©fÃ©rences :

#### 1. Framework Dash - Structure de base

**Fichier** : `main.py`, lignes 1-30  
**Source** : [Documentation officielle Dash](https://dash.plotly.com/layout)  
**Explication** : Structure de base d'une application Dash avec `app = Dash(__name__)` et `app.layout`. Syntaxe standard du framework.

#### 2. Plotly - Configuration des graphiques

**Fichier** : `src/components/component1.py`, lignes 15-25  
**Source** : [Documentation Plotly Subplots](https://plotly.com/python/subplots/)  
**Explication** : Utilisation de `make_subplots()` pour crÃ©er plusieurs graphiques empilÃ©s. Syntaxe officielle de Plotly pour les sous-graphiques.

```python
fig = make_subplots(rows=n, cols=1, subplot_titles=[...])
```

#### 3. Pandas - Groupby et agrÃ©gations

**Fichier** : `src/components/component2.py`, ligne 12  
**Source** : [Documentation Pandas](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)  
**Explication** : AgrÃ©gation par groupe avec `.groupby().mean().reset_index()`. Syntaxe standard Pandas.

```python
means = df.groupby(SIZE_COLUMN)[NOTE_COLUMNS].mean().reset_index()
```

#### 4. Plotly Express - Animations

**Fichier** : `src/components/component3.py`, lignes 10-20  
**Source** : [Plotly Animation Documentation](https://plotly.com/python/animations/)  
**Explication** : ParamÃ¨tre `animation_frame` pour crÃ©er des animations temporelles dans Plotly Express.

```python
fig = px.scatter(df, animation_frame=YEAR_COLUMN, ...)
```

#### 5. CSS - Flexbox pour le footer

**Fichier** : `src/components/footer.py`, lignes 50-55  
**Source** : [MDN Web Docs - Flexbox](https://developer.mozilla.org/fr/docs/Web/CSS/CSS_Flexible_Box_Layout)  
**Explication** : Utilisation de `display: flex` et `justifyContent: 'space-around'` pour aligner les Ã©lÃ©ments du footer.

```python
style={'display': 'flex', 'justifyContent': 'space-around'}
```

#### 7. SQLAlchemy - ORM et connexion SQLite

**Fichier** : `db.py`, lignes 8-10  
**Source** : [Documentation SQLAlchemy](https://docs.sqlalchemy.org/en/20/core/engines.html)  
**Explication** : CrÃ©ation d'un moteur SQLAlchemy pour se connecter Ã  SQLite. `create_engine()` avec le paramÃ¨tre `future=True` active le mode SQLAlchemy 2.0.

```python
from sqlalchemy import create_engine
engine = create_engine(DB_URL, future=True)
```

#### 8. Pandas - Lecture/Ã‰criture SQL

**Fichier** : `db.py`, lignes 18-20 et 26-28  
**Source** : [Pandas SQL Documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html)  
**Explication** : Utilisation de `to_sql()` pour Ã©crire un DataFrame dans SQLite et `read_sql()` pour lire depuis une table SQL.

```python
df.to_sql(table, engine, if_exists="replace", index=False)
df = pd.read_sql(f"SELECT * FROM {table}", con=engine)
```

#### 9. Requests - TÃ©lÃ©chargement HTTP

**Fichier** : `src/utils/get_data.py`, lignes 20-25  
**Source** : [Documentation Requests](https://requests.readthedocs.io/)  
**Explication** : Utilisation de `requests.get()` pour tÃ©lÃ©charger un fichier depuis une URL et `response.content` pour rÃ©cupÃ©rer les donnÃ©es binaires.

```python
response = requests.get(DATA_URL)
with open(EXCEL_PATH, "wb") as f:
    f.write(response.content)
```

#### 10. Regex - Extraction de nombres

**Fichier** : `src/utils/clean_data.py`, lignes 20-25  
**Source** : [Python re module](https://docs.python.org/3/library/re.html)  
**Explication** : Expression rÃ©guliÃ¨re `r"\d+(\.\d+)?"` pour extraire le premier nombre dÃ©cimal d'une chaÃ®ne. UtilisÃ© pour nettoyer les colonnes de notes.

```python
match = re.search(r"\d+(\.\d+)?", str(val))
if match:
    return float(match.group())
```

### DÃ©claration finale

**Toute ligne non dÃ©clarÃ©e ci-dessus est rÃ©putÃ©e Ãªtre produite par l'auteur (ou les auteurs) du projet.**

L'absence ou l'omission de dÃ©claration sera considÃ©rÃ©e comme du plagiat.

**Auteurs** :
- OUCHAOU Lina
- POGEANT Justine

**Date** : Novembre 2025  
**Projet** : Dashboard Ã‰galitÃ© Professionnelle - Python 2025

---

<div align="center">

**Fait avec â¤ï¸ par OUCHAOU Lina & POGEANT Justine**

*Dashboard Ã‰galitÃ© Professionnelle 2025*

---

ğŸ“§ Contact : [lina.ouchaou@edu.esiee.fr](lina.ouchaou@edu.esiee.fr) et [justine.pogeant@edu.esiee.fr](justine.pogeant@edu.esiee.fr)

ğŸ’» GitHub : [https://github.com/LinaOuchaouAmroussi/projet_data.git](https://github.com/LinaOuchaouAmroussi/projet_data.git)

</div>